{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4139805,"sourceType":"datasetVersion","datasetId":2445309}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/melihkotman/bank-churn-xgboost-vs-rf-threshold-tuning?scriptVersionId=297223416\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBClassifier\nfrom keras.src.trainers.data_adapters.data_adapter_utils import class_weight_to_sample_weights\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\n\ndata = pd.read_csv(\"/kaggle/input/bank-customer-churn-dataset/Bank Customer Churn Prediction.csv\")\ndf = pd.DataFrame(data)\nprint(df.head(10))\nprint(df.columns)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-11T21:15:32.364359Z","iopub.execute_input":"2026-02-11T21:15:32.364701Z","iopub.status.idle":"2026-02-11T21:15:54.857122Z","shell.execute_reply.started":"2026-02-11T21:15:32.36467Z","shell.execute_reply":"2026-02-11T21:15:54.856293Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis â€“ EDA (KeÅŸifsel Veri Analizi)","metadata":{}},{"cell_type":"code","source":"# Null Value Control\nprint(\"Null value summary:\")\nprint(df.isnull().sum())\n\n\n# Churn vs Balance\nplt.figure(figsize=(10, 6))\n\n# Churn = 0\nsns.kdeplot(\n    data = df[df['churn'] == 0],\n    x = 'balance',\n    fill = True, # EÄŸrinin altÄ±nÄ± boyar\n    color = 'blue',\n    label = 'Kalanlar (0)',\n    alpha = 0.3\n)\n\n# Churn = 1\nsns.kdeplot(\n    data = df[df['churn'] == 1],\n    x = 'balance',\n    fill = True, # EÄŸrinin altÄ±nÄ± boyar\n    color = 'red',\n    label = 'Gidenler (1)', \n    alpha = 0.3\n)\n\nplt.title(\"Bakiye DaÄŸÄ±lÄ±mÄ±: Gidenler vs Kalanlar\")\nplt.xlabel(\"Bakiye\")\nplt.ylabel(\"YoÄŸunluk\")\nplt.legend()\nplt.show()\n\n# Age vs Churn\ndf['age_group'] = pd.cut(\n    df['age'],\n    bins = [18, 30, 45, 60, 100],\n    labels = ['GenÃ§ (18-30)','YetiÅŸkin (30-45)', 'Orta YaÅŸ (45-60)', 'YaÅŸlÄ± (60-100)']\n) # cut ile birlikte sÃ¼tundaki bilgiyi verilen bÃ¶lÃ¼m aralÄ±klarÄ±na ayÄ±rÄ±r ve gruplar\n\nplt.figure(figsize=(10, 6))\nsns.countplot(\n    data = df,\n    x = 'age_group',\n    hue = 'churn', # Hedef deÄŸiÅŸken\n    palette = 'magma'\n)\nplt.title(\"YaÅŸ GruplarÄ±na GÃ¶re MÃ¼ÅŸteri KaybÄ±\")\nplt.xlabel(\"YaÅŸ Grubu\")\nplt.ylabel(\"KiÅŸi SayÄ±sÄ±\")\nplt.legend(title='Durum', labels=[\"KaldÄ± (0)\", \"Gitti (1)\"])\nplt.show()\n\n\n# Gender vs Churn\nplt.figure(figsize=(8, 5))\nax = sns.countplot(\n    data = df,\n    x = 'gender',\n    hue = 'churn', # Hedef deÄŸiÅŸken\n    palette = 'pastel'\n)\n\n# Etiketleme (KadÄ±n ve Erkek olarak kaÃ§ kiÅŸi gitmiÅŸ Ã¼zerine yazÄ±lsÄ±n)\nfor container in ax.containers:\n    ax.bar_label(container, fmt = '%d', padding = 3) # SayÄ± formatÄ± fmt ile belirlenir\n\nplt.title(\"Cinsiyete GÃ¶re Churn (Terk Etme) EÄŸilimi\")\nplt.xlabel(\"Cinsiyet\")\nplt.ylabel(\"KiÅŸi SayÄ±sÄ±\")\nplt.legend(title = \"Churn\", labels = [\"KaldÄ± (0)\", \"Gitti (1)\"])\nplt.show()\n\n# Country vs Churn\nplt.figure(figsize=(8, 5))\nax = sns.countplot(\n    data = df,\n    x = 'country',\n    hue = 'churn',\n    palette = 'Set2'\n)\n\n# Etiketleme (Hangi Ã¼lkeden kaÃ§ kiÅŸi gitmiÅŸ Ã¼zerine yazÄ±lsÄ±n)\nfor container in ax.containers:\n    ax.bar_label(container, fmt='%d', padding = 2) # SayÄ± formatÄ± fmt ile belirlenir\n\nplt.title(\"Ãœlkelere GÃ¶re MÃ¼ÅŸteri KaybÄ±\")\nplt.xlabel(\"Ãœlke\")\nplt.ylabel(\"MÃ¼ÅŸteri SayÄ±sÄ±\")\nplt.legend(title='Durum', labels=[\"KaldÄ±\", \"Gitti\"])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T21:15:54.858654Z","iopub.execute_input":"2026-02-11T21:15:54.858946Z","iopub.status.idle":"2026-02-11T21:15:55.899044Z","shell.execute_reply.started":"2026-02-11T21:15:54.858919Z","shell.execute_reply":"2026-02-11T21:15:55.8983Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Insights\n\n###  Insights on Balance\n* **Zero Balance Stability:** As seen in the KDE plot, a significant portion of customers with **0 balance** tends to stay (`Churn=0`). This might indicate inactive users or credit card-only users who are less likely to leave.\n* **High Balance Risk:** Surprisingly, customers with a balance between **100k - 150k** show a higher tendency to churn. This could imply that customers with higher savings are more sensitive to interest rates or competitive offers from other banks.\n\n### ðŸ’¡ Insights on Age\n* **Young & Adults:** The retention rate is higher among younger customers and adults.\n* **Middle-Age Crisis:** There is a critical crossover point around **middle age (40-50s)** where the number of churners surpasses the number of retained customers. This suggests that the bank is losing its most financially mature audience.\n\n### ðŸ’¡ Insights on Gender\n* **Proportionality:** While the dataset is somewhat balanced, **Female** customers show a slightly higher churn rate compared to **Males**.\n* **Male Retention:** Men tend to stay with the bank more often than women. This might require a targeted marketing strategy for female customers.\n\n### ðŸ’¡ Insights on Geography\n* **France & Spain:** These countries have relatively lower and stable churn rates.\n* **The German Problem:** **Germany** exhibits a significantly higher churn rate compared to others. This is a major red flag. It could be due to local competition, lack of branch support, or specific dissatisfaction among German customers.","metadata":{}},{"cell_type":"markdown","source":"# XGBoost Modelling and Feature Engineering","metadata":{}},{"cell_type":"code","source":"# X ve y deÄŸiÅŸkenlerine ayÄ±rÄ±yoruz.\nX = df.drop(['customer_id','churn', 'age_group'], axis = 1)\ny = df['churn']\n\n# Feature Engineering\n# Country -> One-Hot Encoding\n# Gender -> Label Encoding\nX = pd.get_dummies(X, columns=['country'], drop_first = True) # drop_first = True ile dummy variable trap Ã¶nlendi.\n\nle = LabelEncoder()\nX['gender'] = le.fit_transform(df['gender'])\n\n# Train ve Test AyÄ±rmasÄ±\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n# Standard Scaler (Age, Balance)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# XGBoosting\nmodel = XGBClassifier(random_state = 42)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot = True, fmt = 'd', cmap = 'Blues')\nplt.title(\"Confusion Matrix (XGBoost)\")\nplt.xlabel(\"Tahmin Edilen\")\nplt.ylabel(\"GerÃ§ek Durum\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T21:15:55.900081Z","iopub.execute_input":"2026-02-11T21:15:55.900384Z","iopub.status.idle":"2026-02-11T21:15:56.265975Z","shell.execute_reply.started":"2026-02-11T21:15:55.900353Z","shell.execute_reply":"2026-02-11T21:15:56.265152Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The XGBoost model achieved an overall **Accuracy of 87%**, which looks promising at first glance. However, in churn prediction, accuracy can be misleading due to class imbalance (1607 retained vs. 393 churned customers).\n\n##  Key Takeaways:\n* **Strong on Retained Customers (Class 0):** The model identifies customers who stay with high precision (**0.90**) and recall (**0.95**).\n* **The \"Recall\" Problem (Class 1):** The **Recall for Churners is only 0.55**.\n    * **Business Impact:** This means the model captures only **55%** of the customers who are actually leaving. We are missing **45%** of the potential churners!\n    * In a business context, missing a churner (False Negative) is often more costly than falsely flagging a loyal customer (False Positive).","metadata":{}},{"cell_type":"markdown","source":"# Random Forest with class_weight","metadata":{}},{"cell_type":"code","source":"rf_weighted = RandomForestClassifier(\n    n_estimators = 100,\n    class_weight = 'balanced', # SÄ±nÄ±f dengesizliÄŸi iÃ§in aÄŸÄ±rlÄ±klandÄ±rma\n    random_state = 42\n)\n\nrf_weighted.fit(X_train, y_train)\ny_pred_weighted = rf_weighted.predict(X_test)\n\nprint(classification_report(y_test, y_pred_weighted))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(confusion_matrix(y_test, y_pred_weighted), annot = True, fmt = 'd', cmap = 'Blues')\nplt.title(\"Confusion Matrix (Random Forest - Balanced Weight)\")\nplt.xlabel(\"Tahmin Edilen\")\nplt.ylabel(\"GerÃ§ek Durum\")\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T21:15:56.267761Z","iopub.execute_input":"2026-02-11T21:15:56.268147Z","iopub.status.idle":"2026-02-11T21:15:57.827195Z","shell.execute_reply.started":"2026-02-11T21:15:56.268121Z","shell.execute_reply":"2026-02-11T21:15:57.82634Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We applied `class_weight='balanced'` to the Random Forest model to help it focus more on the minority class (Churners).\n\n##  Key Observations:\n* **Unexpected Drop in Recall:** Surprisingly, the **Recall for Churners dropped to 0.46** (lower than XGBoost's 0.55).\n    * This indicates that simply adding class weights was not enough to make the model \"aggressive\" enough in detecting churners.\n    * The model is prioritizing **Precision (0.77)** over Recall, meaning it is very careful not to make false alarms, but it misses more than half of the actual churners.\n\n##  The Problem with Default Threshold (0.50)\nStandard models use a **0.50 probability threshold** to classify a customer as \"Churn\".\n* If Probability > 0.50 -> Churn\n* If Probability < 0.50 -> Stay\n\nHowever, for churn prediction, this is too conservative. We want to catch potential churners even if the probability is **30% or 40%**.\n\nðŸ‘‰ **Solution: Threshold Moving:** We will manually adjust the decision threshold to increase Recall and capture those missed churners.","metadata":{}},{"cell_type":"markdown","source":"# Threshold Moving","metadata":{}},{"cell_type":"code","source":"# Get Prediction Probabilities\n# predict_proba -> [Leave_Rate, Stay_Rate], first index\ny_pred_proba = rf_weighted.predict_proba(X_test)[:, 1]\n\n# Apply New Threshold (0.35)\n# Normal 0.5 -> 0.35\nnew_threshold = 0.35 # yÃ¼zde 35 ihtimal bile gidecek de\ny_pred_new = (y_pred_proba >= new_threshold).astype(int)\n\n# Compare Results\nprint(f\"--- Optimized Results (Threshold {new_threshold}) ---\")\nprint(classification_report(y_test, y_pred_new))\n\n# Confusion matrix Comparison\nplt.figure(figsize=(12, 5))\n\n# Standard Confusion matrix\nplt.subplot(1, 2, 1)\nsns.heatmap(confusion_matrix(y_test, y_pred_weighted), annot = True, fmt='d', cmap = 'Reds')\nplt.title(\"Standard Threshold (0.50)\\n High Precision, Low Recall\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\n\nplt.subplot(1, 2, 2)\nsns.heatmap(confusion_matrix(y_test, y_pred_new), annot = True, fmt= 'd', cmap = 'Greens')\nplt.title(f\"Adjusted Threshold ({new_threshold})\\n Gain Recall\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T21:25:51.869375Z","iopub.execute_input":"2026-02-11T21:25:51.870123Z","iopub.status.idle":"2026-02-11T21:25:52.293913Z","shell.execute_reply.started":"2026-02-11T21:25:51.870089Z","shell.execute_reply":"2026-02-11T21:25:52.293076Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"By lowering the decision threshold from **0.50** to **0.35**, we successfully shifted the model's focus to capture more churners.\n\n##  Comparative Results (Churn Class '1'):\n* **Standard RF (0.50):** Recall = **0.46** (Missed more than half!)\n* **Optimized RF (0.35):** Recall = **0.60** (Significant Improvement)\n\n##  Business Impact:\n*  **Gain:** We are now catching **60%** of the potential churners, compared to only 46% before. This allows the bank to take proactive measures (e.g., offering better rates) for a larger group of at-risk customers.\n*  **Trade-off:** Precision dropped from **0.77** to **0.62**. This means we will make some \"False Positive\" calls (flagging loyal customers as churners). However, in customer retention strategies, sending a \"Thank You\" email or a small offer to a loyal customer is usually a safe and low-cost action compared to losing a valuable client.\n\n##  Final Verdict\nThe **Random Forest model with Class Weighting and Threshold Tuning** provides the most actionable insights for the bank, striking a strategic balance between catching churners and maintaining reasonable accuracy.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}